{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1p8d63lRS-CYHYnDAEcRTRCQBj8kqsDXf",
      "authorship_tag": "ABX9TyMr737cQDdWIhEwikROLMxQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gilangp/Machine-learning/blob/main/KUIS%202/KUIS2_2341720042_Gilang_Purnomo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Klasifikasi Jenis Sayur**"
      ],
      "metadata": {
        "id": "-LqnMG24N-yh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import Library**"
      ],
      "metadata": {
        "id": "Hn0-NKnXOTLy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mb_rX5g2NhML"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import cv2 as cv\n",
        "import os\n",
        "import joblib\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Dataset**"
      ],
      "metadata": {
        "id": "yd5EbPMdOiwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/drive/MyDrive/Colab Notebooks/Machine Learning/Vegetable Images/train\"\n",
        "\n",
        "class_names = os.listdir(train_dir)\n",
        "print(\"Class names:\", class_names)\n",
        "print(\"Number of classes:\", len(class_names))\n",
        "\n",
        "train_counts = []\n",
        "\n",
        "for class_name in class_names:\n",
        "    train_path = os.path.join(train_dir, class_name)\n",
        "    train_count = len(os.listdir(train_path))\n",
        "    train_counts.append(train_count)\n",
        "\n",
        "print(\"\\nTraining images per class:\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "    print(f\"{class_name}: {train_counts[i]} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07T8e6s2Oj8k",
        "outputId": "131f805a-03bc-4c50-9954-adbd42c21526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class names: ['Radish', 'Tomato', 'Potato', 'Cauliflower', 'Pumpkin', 'Cucumber', 'Papaya', 'Cabbage', 'Carrot', 'Capsicum', 'Broccoli', 'Brinjal', 'Bean', 'Bitter_Gourd', 'Bottle_Gourd']\n",
            "Number of classes: 15\n",
            "\n",
            "Training images per class:\n",
            "Radish: 1000 images\n",
            "Tomato: 1014 images\n",
            "Potato: 1000 images\n",
            "Cauliflower: 1001 images\n",
            "Pumpkin: 1014 images\n",
            "Cucumber: 1000 images\n",
            "Papaya: 1000 images\n",
            "Cabbage: 1014 images\n",
            "Carrot: 1000 images\n",
            "Capsicum: 1000 images\n",
            "Broccoli: 1016 images\n",
            "Brinjal: 1000 images\n",
            "Bean: 1000 images\n",
            "Bitter_Gourd: 1000 images\n",
            "Bottle_Gourd: 1001 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pra Pengolahan Data**"
      ],
      "metadata": {
        "id": "p_-a_V74PDIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "img_size = (128, 128)\n",
        "max_images_per_class = 200  # Batasi untuk efisiensi\n",
        "\n",
        "print(\"Loading and preprocessing training images...\")\n",
        "\n",
        "for class_idx, class_name in enumerate(class_names):\n",
        "    class_path = os.path.join(train_dir, class_name)\n",
        "    image_files = os.listdir(class_path)\n",
        "\n",
        "    for img_file in image_files:\n",
        "        img_path = os.path.join(class_path, img_file)\n",
        "\n",
        "        img = cv.imread(img_path)\n",
        "        if img is not None:\n",
        "            img = cv.resize(img, img_size)\n",
        "            img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "            img = img / 255.0\n",
        "\n",
        "            # Preprocessing enhancements\n",
        "            img = cv.convertScaleAbs((img * 255).astype(np.uint8), alpha=1.2, beta=10)\n",
        "            img = img / 255.0\n",
        "            img = cv.GaussianBlur(img, (3, 3), 0)\n",
        "\n",
        "            X_train.append(img)\n",
        "            y_train.append(class_idx)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlgykji0PEqZ",
        "outputId": "da109dc3-d5f1-437b-916a-bd3f21c42ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing training images...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ekstraksi Fitur**"
      ],
      "metadata": {
        "id": "CyKG0sHJPr81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract color features\n",
        "color_features = []\n",
        "\n",
        "for img in X_train:\n",
        "    hsv = cv.cvtColor((img * 255).astype(np.uint8), cv.COLOR_RGB2HSV)\n",
        "\n",
        "    h_mean, h_std = np.mean(hsv[:,:,0]), np.std(hsv[:,:,0])\n",
        "    s_mean, s_std = np.mean(hsv[:,:,1]), np.std(hsv[:,:,1])\n",
        "    v_mean, v_std = np.mean(hsv[:,:,2]), np.std(hsv[:,:,2])\n",
        "\n",
        "    hist_h = cv.calcHist([hsv], [0], None, [8], [0, 180]).flatten()\n",
        "    hist_s = cv.calcHist([hsv], [1], None, [8], [0, 256]).flatten()\n",
        "    hist_v = cv.calcHist([hsv], [2], None, [8], [0, 256]).flatten()\n",
        "\n",
        "    color_feature = np.array([h_mean, h_std, s_mean, s_std, v_mean, v_std])\n",
        "    color_feature = np.concatenate([color_feature, hist_h, hist_s, hist_v])\n",
        "    color_features.append(color_feature)\n",
        "\n",
        "color_features = np.array(color_features)\n",
        "\n",
        "# Extract texture features\n",
        "texture_features = []\n",
        "\n",
        "for img in X_train:\n",
        "    gray = cv.cvtColor((img * 255).astype(np.uint8), cv.COLOR_RGB2GRAY)\n",
        "    mean_val = np.mean(gray)\n",
        "    std_val = np.std(gray)\n",
        "    entropy_val = -np.sum(gray * np.log2(gray + 1e-8))\n",
        "    texture_feature = np.array([mean_val, std_val, entropy_val])\n",
        "    texture_features.append(texture_feature)\n",
        "\n",
        "texture_features = np.array(texture_features)\n",
        "\n",
        "# Combine features\n",
        "X_features = np.concatenate([color_features, texture_features], axis=1)\n",
        "print(f\"Combined features shape: {X_features.shape}\")\n",
        "\n",
        "# Standardize and apply PCA\n",
        "scaler = StandardScaler()\n",
        "X_features_scaled = scaler.fit_transform(X_features)\n",
        "\n",
        "pca = PCA(n_components=0.95)\n",
        "X_features_pca = pca.fit_transform(X_features_scaled)\n",
        "\n",
        "print(f\"Features after PCA: {X_features_pca.shape}\")"
      ],
      "metadata": {
        "id": "h7gn_f82Pv4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model dengan Semua Metode Split**"
      ],
      "metadata": {
        "id": "0vUvaIe1dFaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inisialisasi Model**"
      ],
      "metadata": {
        "id": "1iQ1Rq-gdLvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC(kernel='rbf', random_state=42, probability=True)\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "models = {\n",
        "    'SVM': svm_model,\n",
        "    'Random Forest': rf_model\n",
        "}"
      ],
      "metadata": {
        "id": "77hu3ojxdPRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metode Split 70:30**"
      ],
      "metadata": {
        "id": "7xHfFlwQdOWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr_70, X_te_70, y_tr_70, y_te_70 = train_test_split(\n",
        "    X_features_pca, y_train,\n",
        "    train_size=0.7,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y_train\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(y_tr_70)}\")\n",
        "print(f\"Testing samples: {len(y_te_70)}\")\n",
        "\n",
        "results_70 = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.fit(X_tr_70, y_tr_70)\n",
        "    y_pred = model.predict(X_te_70)\n",
        "    y_pred_proba = model.predict_proba(X_te_70)\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    accuracy = accuracy_score(y_te_70, y_pred)\n",
        "    precision = precision_score(y_te_70, y_pred, average='weighted')\n",
        "    recall = recall_score(y_te_70, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_te_70, y_pred, average='weighted')\n",
        "\n",
        "    results_70[model_name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'training_time': training_time\n",
        "    }\n",
        "\n",
        "    print(f\"{model_name} Results:\")\n",
        "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall:    {recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {f1:.4f}\")\n",
        "    print(f\"  Time:      {training_time:.2f}s\")\n",
        "\n",
        "# Create results DataFrame for 70:30\n",
        "results_70_df = pd.DataFrame(results_70).T\n",
        "print(\"\\nSummary 70:30 Split:\")\n",
        "print(results_70_df)"
      ],
      "metadata": {
        "id": "rReAAmYKdThB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metode Split 80:20**"
      ],
      "metadata": {
        "id": "EgLurahtdg3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data 80:20\n",
        "X_tr_80, X_te_80, y_tr_80, y_te_80 = train_test_split(\n",
        "    X_features_pca, y_train,\n",
        "    train_size=0.8,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_train\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(y_tr_80)}\")\n",
        "print(f\"Testing samples: {len(y_te_80)}\")\n",
        "\n",
        "results_80 = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create new instance for this split\n",
        "    if model_name == 'SVM':\n",
        "        current_model = SVC(kernel='rbf', random_state=42, probability=True)\n",
        "    else:\n",
        "        current_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    current_model.fit(X_tr_80, y_tr_80)\n",
        "    y_pred = current_model.predict(X_te_80)\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    accuracy = accuracy_score(y_te_80, y_pred)\n",
        "    precision = precision_score(y_te_80, y_pred, average='weighted')\n",
        "    recall = recall_score(y_te_80, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_te_80, y_pred, average='weighted')\n",
        "\n",
        "    results_80[model_name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'training_time': training_time,\n",
        "        'model': current_model\n",
        "    }\n",
        "\n",
        "    print(f\"{model_name} Results:\")\n",
        "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall:    {recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {f1:.4f}\")\n",
        "    print(f\"  Time:      {training_time:.2f}s\")\n",
        "\n",
        "# Create results DataFrame for 80:20\n",
        "results_80_df = pd.DataFrame(results_80).T\n",
        "print(\"\\nSummary 80:20 Split:\")\n",
        "print(results_80_df)"
      ],
      "metadata": {
        "id": "sCnktkk5diMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metode Split 90:10**"
      ],
      "metadata": {
        "id": "AgVlxZxtdjGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data 90:10\n",
        "X_tr_90, X_te_90, y_tr_90, y_te_90 = train_test_split(\n",
        "    X_features_pca, y_train,\n",
        "    train_size=0.9,\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    stratify=y_train\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(y_tr_90)}\")\n",
        "print(f\"Testing samples: {len(y_te_90)}\")\n",
        "\n",
        "results_90 = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create new instance for this split\n",
        "    if model_name == 'SVM':\n",
        "        current_model = SVC(kernel='rbf', random_state=42, probability=True)\n",
        "    else:\n",
        "        current_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    current_model.fit(X_tr_90, y_tr_90)\n",
        "    y_pred = current_model.predict(X_te_90)\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    accuracy = accuracy_score(y_te_90, y_pred)\n",
        "    precision = precision_score(y_te_90, y_pred, average='weighted')\n",
        "    recall = recall_score(y_te_90, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_te_90, y_pred, average='weighted')\n",
        "\n",
        "    results_90[model_name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'training_time': training_time,\n",
        "        'model': current_model\n",
        "    }\n",
        "\n",
        "    print(f\"{model_name} Results:\")\n",
        "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall:    {recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {f1:.4f}\")\n",
        "    print(f\"  Time:      {training_time:.2f}s\")\n",
        "\n",
        "# Create results DataFrame for 90:10\n",
        "results_90_df = pd.DataFrame(results_90).T\n",
        "print(\"\\nSummary 90:10 Split:\")\n",
        "print(results_90_df)"
      ],
      "metadata": {
        "id": "YMrbbeSBdlap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross-Validation dengan k=5**"
      ],
      "metadata": {
        "id": "smjuoERfdnrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nPerforming 5-fold CV for {model_name}...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Perform cross-validation with multiple metrics\n",
        "    scoring = {'accuracy': 'accuracy',\n",
        "               'precision': 'precision_weighted',\n",
        "               'recall': 'recall_weighted',\n",
        "               'f1': 'f1_weighted'}\n",
        "\n",
        "    cv_scores = cross_validate(model, X_features_pca, y_train,\n",
        "                              cv=5, scoring=scoring,\n",
        "                              return_train_score=False, n_jobs=-1)\n",
        "\n",
        "    cv_time = time.time() - start_time\n",
        "\n",
        "    cv_results[model_name] = {\n",
        "        'cv_accuracy_mean': np.mean(cv_scores['test_accuracy']),\n",
        "        'cv_accuracy_std': np.std(cv_scores['test_accuracy']),\n",
        "        'cv_precision_mean': np.mean(cv_scores['test_precision']),\n",
        "        'cv_precision_std': np.std(cv_scores['test_precision']),\n",
        "        'cv_recall_mean': np.mean(cv_scores['test_recall']),\n",
        "        'cv_recall_std': np.std(cv_scores['test_recall']),\n",
        "        'cv_f1_mean': np.mean(cv_scores['test_f1']),\n",
        "        'cv_f1_std': np.std(cv_scores['test_f1']),\n",
        "        'cv_time': cv_time\n",
        "    }\n",
        "\n",
        "    print(f\"{model_name} CV Results:\")\n",
        "    print(f\"  Accuracy:  {cv_results[model_name]['cv_accuracy_mean']:.4f} (±{cv_results[model_name]['cv_accuracy_std']:.4f})\")\n",
        "    print(f\"  Precision: {cv_results[model_name]['cv_precision_mean']:.4f} (±{cv_results[model_name]['cv_precision_std']:.4f})\")\n",
        "    print(f\"  Recall:    {cv_results[model_name]['cv_recall_mean']:.4f} (±{cv_results[model_name]['cv_recall_std']:.4f})\")\n",
        "    print(f\"  F1-Score:  {cv_results[model_name]['cv_f1_mean']:.4f} (±{cv_results[model_name]['cv_f1_std']:.4f})\")\n",
        "    print(f\"  Time:      {cv_time:.2f}s\")\n",
        "\n",
        "# Create CV results DataFrame\n",
        "cv_results_df = pd.DataFrame(cv_results).T\n",
        "print(\"\\nSummary Cross-Validation:\")\n",
        "print(cv_results_df)"
      ],
      "metadata": {
        "id": "CoWFp3fndoxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Perbandingan Semua Metode**"
      ],
      "metadata": {
        "id": "QOTjTgsUd4kN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for visualization\n",
        "split_methods = ['70:30', '80:20', '90:10', 'CV-5']\n",
        "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_data = []\n",
        "\n",
        "for model_name in ['SVM', 'Random Forest']:\n",
        "    for metric in metrics:\n",
        "        row = {'Model': model_name, 'Metric': metric}\n",
        "\n",
        "        # Add results for each split method\n",
        "        row['70:30'] = results_70[model_name][metric]\n",
        "        row['80:20'] = results_80[model_name][metric]\n",
        "        row['90:10'] = results_90[model_name][metric]\n",
        "\n",
        "        # For CV, use mean values\n",
        "        cv_metric_map = {'accuracy': 'cv_accuracy_mean',\n",
        "                        'precision': 'cv_precision_mean',\n",
        "                        'recall': 'cv_recall_mean',\n",
        "                        'f1_score': 'cv_f1_mean'}\n",
        "        row['CV-5'] = cv_results[model_name][cv_metric_map[metric]]\n",
        "\n",
        "        comparison_data.append(row)\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"\\nComparison DataFrame:\")\n",
        "print(comparison_df)\n",
        "\n",
        "# Visualization 1: Accuracy comparison across methods\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot for each model\n",
        "for i, model_name in enumerate(['SVM', 'Random Forest']):\n",
        "    model_data = comparison_df[comparison_df['Model'] == model_name]\n",
        "    acc_data = model_data[model_data['Metric'] == 'accuracy']\n",
        "\n",
        "    methods = ['70:30', '80:20', '90:10', 'CV-5']\n",
        "    acc_values = [acc_data[method].values[0] for method in methods]\n",
        "\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    bars = plt.bar(methods, acc_values, color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
        "    plt.title(f'{model_name} - Accuracy Comparison')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.ylim(0, 1)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, value in zip(bars, acc_values):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{value:.4f}', ha='center', va='bottom')\n",
        "\n",
        "# Plot for F1-Score comparison\n",
        "for i, model_name in enumerate(['SVM', 'Random Forest']):\n",
        "    model_data = comparison_df[comparison_df['Model'] == model_name]\n",
        "    f1_data = model_data[model_data['Metric'] == 'f1_score']\n",
        "\n",
        "    methods = ['70:30', '80:20', '90:10', 'CV-5']\n",
        "    f1_values = [f1_data[method].values[0] for method in methods]\n",
        "\n",
        "    plt.subplot(2, 2, i+3)\n",
        "    bars = plt.bar(methods, f1_values, color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
        "    plt.title(f'{model_name} - F1-Score Comparison')\n",
        "    plt.ylabel('F1-Score')\n",
        "    plt.ylim(0, 1)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, value in zip(bars, f1_values):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{value:.4f}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualization 2: Detailed metrics for best split method (80:20)\n",
        "best_split_results = results_80_df\n",
        "metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1_score']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "x = np.arange(len(metrics_to_plot))\n",
        "width = 0.35\n",
        "\n",
        "svm_scores = [best_split_results.loc['SVM', metric] for metric in metrics_to_plot]\n",
        "rf_scores = [best_split_results.loc['Random Forest', metric] for metric in metrics_to_plot]\n",
        "\n",
        "plt.bar(x - width/2, svm_scores, width, label='SVM', alpha=0.8)\n",
        "plt.bar(x + width/2, rf_scores, width, label='Random Forest', alpha=0.8)\n",
        "\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Model Performance Comparison (80:20 Split)')\n",
        "plt.xticks(x, ['Accuracy', 'Precision', 'Recall', 'F1-Score'])\n",
        "plt.legend()\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for i, v in enumerate(svm_scores):\n",
        "    plt.text(i - width/2, v + 0.01, f'{v:.4f}', ha='center')\n",
        "for i, v in enumerate(rf_scores):\n",
        "    plt.text(i + width/2, v + 0.01, f'{v:.4f}', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QMHLjzlSd7q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hyperparameter Tuning untuk Model Terbaik**"
      ],
      "metadata": {
        "id": "zUQRudked9ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use 80:20 split for tuning (based on previous results)\n",
        "X_tr_tune = X_tr_80\n",
        "y_tr_tune = y_tr_80\n",
        "X_te_tune = X_te_80\n",
        "y_te_tune = y_te_80\n",
        "\n",
        "# Hyperparameter tuning for SVM\n",
        "print(\"Performing GridSearchCV for SVM...\")\n",
        "\n",
        "param_grid_svm = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [0.001, 0.01, 0.1, 1],\n",
        "    'kernel': ['rbf', 'linear']\n",
        "}\n",
        "\n",
        "svm_tune = SVC(random_state=42, probability=True)\n",
        "grid_svm = GridSearchCV(svm_tune, param_grid_svm, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "start_time = time.time()\n",
        "grid_svm.fit(X_tr_tune, y_tr_tune)\n",
        "tuning_time = time.time() - start_time\n",
        "\n",
        "print(\"Best SVM parameters:\", grid_svm.best_params_)\n",
        "print(\"Best SVM score:\", grid_svm.best_score_)\n",
        "print(f\"Tuning time: {tuning_time:.2f}s\")\n",
        "\n",
        "# Train best model\n",
        "best_svm = grid_svm.best_estimator_\n",
        "y_pred_tune = best_svm.predict(X_te_tune)\n",
        "\n",
        "# Evaluate tuned model\n",
        "tuned_accuracy = accuracy_score(y_te_tune, y_pred_tune)\n",
        "tuned_precision = precision_score(y_te_tune, y_pred_tune, average='weighted')\n",
        "tuned_recall = recall_score(y_te_tune, y_pred_tune, average='weighted')\n",
        "tuned_f1 = f1_score(y_te_tune, y_pred_tune, average='weighted')\n",
        "\n",
        "print(\"\\nTuned SVM Results:\")\n",
        "print(f\"Accuracy:  {tuned_accuracy:.4f}\")\n",
        "print(f\"Precision: {tuned_precision:.4f}\")\n",
        "print(f\"Recall:    {tuned_recall:.4f}\")\n",
        "print(f\"F1-Score:  {tuned_f1:.4f}\")\n",
        "\n",
        "# Compare with default SVM\n",
        "default_svm_accuracy = results_80['SVM']['accuracy']\n",
        "improvement = tuned_accuracy - default_svm_accuracy\n",
        "print(f\"Improvement after tuning: {improvement:.4f}\")"
      ],
      "metadata": {
        "id": "i7sqnVHgeBMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Simpan Model Terbaik**"
      ],
      "metadata": {
        "id": "weve0BvaeEL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best tuned model and preprocessing objects\n",
        "joblib.dump(best_svm, 'best_vegetable_classifier_svm.pkl')\n",
        "joblib.dump(scaler, 'feature_scaler.pkl')\n",
        "joblib.dump(pca, 'pca_transformer.pkl')\n",
        "\n",
        "print(\"Best model and preprocessing objects saved successfully!\")\n",
        "print(\"Files created:\")\n",
        "print(\"- best_vegetable_classifier_svm.pkl\")\n",
        "print(\"- feature_scaler.pkl\")\n",
        "print(\"- pca_transformer.pkl\")\n",
        "\n",
        "# Verify loading\n",
        "loaded_model = joblib.load('best_vegetable_classifier_svm.pkl')\n",
        "loaded_scaler = joblib.load('feature_scaler.pkl')\n",
        "loaded_pca = joblib.load('pca_transformer.pkl')\n",
        "\n",
        "print(\"Model verification - loaded successfully!\")"
      ],
      "metadata": {
        "id": "LEb-RIiqeGZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final comparison table\n",
        "final_comparison = pd.DataFrame()\n",
        "\n",
        "for split_method in ['70:30', '80:20', '90:10']:\n",
        "    for model_name in ['SVM', 'Random Forest']:\n",
        "        if split_method == '70:30':\n",
        "            results = results_70[model_name]\n",
        "        elif split_method == '80:20':\n",
        "            results = results_80[model_name]\n",
        "        else:\n",
        "            results = results_90[model_name]\n",
        "\n",
        "        final_comparison.loc[model_name, f'{split_method}_Accuracy'] = results['accuracy']\n",
        "        final_comparison.loc[model_name, f'{split_method}_F1'] = results['f1_score']\n",
        "\n",
        "# Add CV results\n",
        "final_comparison.loc['SVM', 'CV_Accuracy'] = cv_results['SVM']['cv_accuracy_mean']\n",
        "final_comparison.loc['SVM', 'CV_F1'] = cv_results['SVM']['cv_f1_mean']\n",
        "final_comparison.loc['Random Forest', 'CV_Accuracy'] = cv_results['Random Forest']['cv_accuracy_mean']\n",
        "final_comparison.loc['Random Forest', 'CV_F1'] = cv_results['Random Forest']['cv_f1_mean']\n",
        "\n",
        "print(\"\\nFINAL COMPARISON TABLE:\")\n",
        "print(final_comparison.round(4))\n",
        "\n",
        "# Determine best method and model\n",
        "best_accuracy = 0\n",
        "best_method = \"\"\n",
        "best_model = \"\"\n",
        "\n",
        "for split_method in ['70:30', '80:20', '90:10']:\n",
        "    for model_name in ['SVM', 'Random Forest']:\n",
        "        accuracy = final_comparison.loc[model_name, f'{split_method}_Accuracy']\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_method = split_method\n",
        "            best_model = model_name\n",
        "\n",
        "print(f\"\\nBEST COMBINATION:\")\n",
        "print(f\"Model: {best_model}\")\n",
        "print(f\"Split Method: {best_method}\")\n",
        "print(f\"Accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\nBEST TUNED MODEL (SVM):\")\n",
        "print(f\"Accuracy: {tuned_accuracy:.4f}\")\n",
        "print(f\"Parameters: {grid_svm.best_params_}\")"
      ],
      "metadata": {
        "id": "SNG5gKBweLGA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}